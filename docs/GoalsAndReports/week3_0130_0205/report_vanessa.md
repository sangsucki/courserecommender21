One of my goals last week was to look into latent features of SVD. After looking at some latent features, it was nearly impossible to determine what these features represented in the latent space. This is seen in the `looking at course feature matrix` commit. Another one of my goals was to test a simple logistic regression model. After researching on logistic regression for recommendation engines, there was minimal resources. Furthermore, after consulting with Dataiku, the major issue with this approach would be that the target feature (classes) has too many options. With hundreds and even thousands of classes, this would be a multiclass logistic regression with too many target variables.

We had also previously discussed shifting to the current time frame of data (2012-2020) and generalizing models to different subsets of data. This week I cleaned and reformatted the current set of data to be able to feed into models (commit called `add cleaned 2013-2020 data`). Then, I subsetted for the economics students in the time frame with complete 4 year data and ran this subset through SVD (commit called `add svd on 2013-2020 econ`). It had similar performance to the earlier 2000-2012 subset. [Ilona: meaning that it is impossible to determine what these features represent? What is your conclusion? Are you stopping using SVD?]
